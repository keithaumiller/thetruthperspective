<?php

/**
 * @file
 * News Extractor module - Enhanced architecture with separated services.
 * 
 * ARCHITECTURE:
 * - ScrapingService (Sensors): Handles Diffbot API and content extraction
 * - AIProcessingService (Processors): Handles Claude AI analysis and prompt building
 * - DataProcessingService (Levers): Handles field updates, taxonomy, and formatting
 * - NewsExtractionService (Orchestrator): Coordinates all services in pipeline
 */

use Drupal\Core\Entity\EntityInterface;
use Drupal\Core\Routing\RouteMatchInterface;
use Drupal\node\Entity\Node;

/**
 * Implements hook_help().
 */
function news_extractor_help($route_name, RouteMatchInterface $route_match) {
  switch ($route_name) {
    case 'help.page.news_extractor':
      return '<p>' . t('Enhanced news extraction with separated scraping, AI processing, and data management services.') . '</p>';
  }
}

/**
 * Implements hook_feeds_process_alter().
 * Alter feed item data before it becomes a node.
 */
function news_extractor_feeds_process_alter(&$feed, $item, $entity_interface) {
  \Drupal::logger('news_extractor')->info('Enhanced news_extractor module - feeds_process_alter triggered');

  // Only process Article content type
  if ($entity_interface->getTarget()->bundle() !== 'article') {
    return;
  }

  $title_to_check = $item['title'] ?? '';
  $link_to_check = $item['link'] ?? '';

  // Use scraping service to validate URLs
  /** @var \Drupal\news_extractor\Service\ScrapingService $scraping_service */
  $scraping_service = \Drupal::service('news_extractor.scraping');

  // Skip invalid URLs
  if (!empty($item['link']) && !$scraping_service->isValidArticleUrl($item['link'])) {
    \Drupal::logger('news_extractor')->info('Skipping invalid article URL: @url', [
      '@url' => $item['link'],
    ]);
    $feed->skipItem($item);
    return;
  }

  // Skip items with blocked content or invalid titles
  if (_news_extractor_has_blocked_content($title_to_check, $link_to_check) ||
      _news_extractor_has_invalid_title($title_to_check)) {
    $feed->skipItem($item);
    return;
  }

  // Extract news source from feed data using service
  /** @var \Drupal\news_extractor\Service\DataProcessingService $data_processing_service */
  $data_processing_service = \Drupal::service('news_extractor.data_processing');
  $news_source = $data_processing_service->extractNewsSourceFromFeed($item);
  
  if (!empty($news_source) && $entity_interface->getTarget()->hasField('field_news_source')) {
    $entity_interface->getTarget()->set('field_news_source', $news_source);
    \Drupal::logger('news_extractor')->info('Set news source from feed: @source', [
      '@source' => $news_source,
    ]);
  }
}

/**
 * Implements hook_entity_insert().
 * Process new article entities.
 */
function news_extractor_entity_insert(EntityInterface $entity) {
  if ($entity->bundle() === 'article' && $entity->hasField('field_original_url')) {
    // Get URL with proper null checking
    $url_field = $entity->get('field_original_url');
    if ($url_field->isEmpty()) {
      \Drupal::logger('news_extractor')->warning('Article created without URL: @title (ID: @id)', [
        '@title' => $entity->getTitle(),
        '@id' => $entity->id(),
      ]);
      return;
    }
    
    $original_url = $url_field->uri;
    
    if (!empty($original_url) && filter_var($original_url, FILTER_VALIDATE_URL)) {
      // Note: News source extraction is handled during Diffbot scraping in ScrapingService::updateMetadataFields()
      // This ensures we have the actual siteName from Diffbot API for accurate source identification
      
      // Use the orchestrator service for complete processing
      /** @var \Drupal\news_extractor\Service\NewsExtractionService $extraction_service */
      $extraction_service = \Drupal::service('news_extractor.extraction');
      $extraction_service->processArticle($entity, $original_url);
    } else {
      \Drupal::logger('news_extractor')->warning('Article created with invalid URL: @url for @title (ID: @id)', [
        '@url' => $original_url,
        '@title' => $entity->getTitle(),
        '@id' => $entity->id(),
      ]);
    }
  }
}

/**
 * Main extraction function using service architecture.
 * 
 * @param \Drupal\Core\Entity\EntityInterface $entity
 *   The article entity to process.
 * @param string $url
 *   The article URL.
 * 
 * @return bool
 *   TRUE if processing was successful.
 */
function _news_extractor_extract_content(EntityInterface $entity, $url) {
  /** @var \Drupal\news_extractor\Service\NewsExtractionService $extraction_service */
  $extraction_service = \Drupal::service('news_extractor.extraction');
  
  return $extraction_service->processArticle($entity, $url);
}

/**
 * Bulk process articles using the new service architecture.
 * 
 * @param int $limit
 *   Maximum number of articles to process.
 * @param string $processing_type
 *   Type of processing: 'full', 'scrape_only', 'analyze_only', 'reprocess'.
 * 
 * @return array
 *   Processing statistics.
 */
function news_extractor_bulk_process_articles($limit = 20, $processing_type = 'full') {
  /** @var \Drupal\news_extractor\Service\NewsExtractionService $extraction_service */
  $extraction_service = \Drupal::service('news_extractor.extraction');
  
  $stats = [
    'processed' => 0,
    'successful' => 0,
    'failed' => 0,
    'skipped' => 0,
  ];

  // Find articles based on processing type
  $query = \Drupal::entityQuery('node')
    ->condition('type', 'article')
    ->accessCheck(FALSE)
    ->range(0, $limit);

  // Customize query based on processing type
  switch ($processing_type) {
    case 'scrape_only':
      // Articles with URLs but no scraped data
      $query->condition('field_original_url.uri', '', '<>');
      $or_group = $query->orConditionGroup();
      $or_group->condition('field_json_scraped_article_data.value', '', '=');
      $or_group->condition('field_json_scraped_article_data.value', NULL, 'IS NULL');
      $query->condition($or_group);
      break;

    case 'analyze_only':
      // Articles with scraped data but no AI analysis
      $query->condition('field_json_scraped_article_data.value', '', '<>');
      $or_group = $query->orConditionGroup();
      $or_group->condition('field_ai_raw_response.value', '', '=');
      $or_group->condition('field_ai_raw_response.value', NULL, 'IS NULL');
      $query->condition($or_group);
      break;

    case 'reprocess':
      // Articles with AI responses for reprocessing
      $query->condition('field_ai_raw_response.value', '', '<>');
      break;

    case 'full':
    default:
      // Articles with URLs but incomplete processing
      $query->condition('field_original_url.uri', '', '<>');
      break;
  }

  $nids = $query->execute();

  foreach ($nids as $nid) {
    $node = Node::load($nid);
    if (!$node) {
      $stats['skipped']++;
      continue;
    }

    $stats['processed']++;
    $success = FALSE;

    try {
      switch ($processing_type) {
        case 'scrape_only':
          $url = $node->get('field_original_url')->uri;
          $success = $extraction_service->scrapeArticleOnly($node, $url);
          break;

        case 'analyze_only':
          $success = $extraction_service->analyzeArticleOnly($node);
          break;

        case 'reprocess':
          $success = $extraction_service->reprocessArticle($node);
          break;

        case 'full':
        default:
          $url = $node->get('field_original_url')->uri;
          $success = $extraction_service->processArticle($node, $url);
          break;
      }

      if ($success) {
        $stats['successful']++;
      } else {
        $stats['failed']++;
      }

    } catch (\Exception $e) {
      $stats['failed']++;
      \Drupal::logger('news_extractor')->error('Error processing node @nid: @error', [
        '@nid' => $nid,
        '@error' => $e->getMessage(),
      ]);
    }
  }

  \Drupal::logger('news_extractor')->info('Bulk processing (@type) complete: @stats', [
    '@type' => $processing_type,
    '@stats' => json_encode($stats),
  ]);

  return $stats;
}

/**
 * Get processing status for articles.
 * 
 * @param int $limit
 *   Number of articles to check.
 * 
 * @return array
 *   Status information for articles.
 */
function news_extractor_get_processing_status($limit = 10) {
  /** @var \Drupal\news_extractor\Service\NewsExtractionService $extraction_service */
  $extraction_service = \Drupal::service('news_extractor.extraction');
  
  $nids = \Drupal::entityQuery('node')
    ->condition('type', 'article')
    ->accessCheck(FALSE)
    ->sort('created', 'DESC')
    ->range(0, $limit)
    ->execute();

  $status_reports = [];
  foreach ($nids as $nid) {
    $node = Node::load($nid);
    if ($node) {
      $status_reports[] = $extraction_service->getProcessingStatus($node);
    }
  }

  return $status_reports;
}

/**
 * Helper function to check for blocked content in title and link.
 */
function _news_extractor_has_blocked_content($title, $link) {
  $blocked_strings = [
    'comparecards.com',
    'fool.com',
    'lendingtree.com',
  ];

  foreach ($blocked_strings as $str) {
    if (stripos($title, $str) !== FALSE) {
      \Drupal::logger('news_extractor')->info('Skipping blocked string in title: @title', [
        '@title' => $title,
      ]);
      return TRUE;
    }
    
    if (stripos($link, $str) !== FALSE) {
      \Drupal::logger('news_extractor')->info('Skipping blocked string in link: @url', [
        '@url' => $link,
      ]);
      return TRUE;
    }
  }

  return FALSE;
}

/**
 * Helper function to check for invalid titles.
 */
function _news_extractor_has_invalid_title($title) {
  // Skip items with missing or empty titles
  if (empty($title) || trim($title) == '') {
    \Drupal::logger('news_extractor')->info('Skipping item with missing or empty title');
    return TRUE;
  }

  // Skip items with very short titles
  if (strlen(trim($title)) < 10) {
    \Drupal::logger('news_extractor')->info('Skipping item with very short title: @title', [
      '@title' => $title,
    ]);
    return TRUE;
  }

  return FALSE;
}

/**
 * Implements hook_cron().
 * 
 * Automated reprocessing of failed articles:
 * 1. Find unpublished articles with processing failures
 * 2. Run them through the complete processing pipeline (Stages 1-6)
 * 3. Delete old unpublished articles that remain failed after 24 hours
 */
function news_extractor_cron() {
  $logger = \Drupal::logger('news_extractor');
  $logger->info('Starting news_extractor automated reprocessing cron job');

  // Get extraction service
  /** @var \Drupal\news_extractor\Service\NewsExtractionService $extraction_service */
  $extraction_service = \Drupal::service('news_extractor.extraction');

  $stats = [
    'published_checked' => 0,
    'articles_unpublished' => 0,
    'unpublished_found' => 0,
    'reprocessed_successfully' => 0,
    'reprocessing_failed' => 0,
    'old_articles_deleted' => 0,
  ];

  // STEP 1: Check published articles for post-processor conditions
  $logger->info('Step 1: Checking published articles for post-processor conditions');
  
  // Find published articles that might need to be unpublished
  // First, get articles with "Analysis is Pending" specifically
  $pending_query = \Drupal::database()->select('node_field_data', 'n');
  $pending_query->leftJoin('node__field_motivation_analysis', 'ma', 'n.nid = ma.entity_id');
  $pending_query->fields('n', ['nid']);
  $pending_query->condition('n.type', 'article');
  $pending_query->condition('n.status', 1); // Only published articles
  $pending_query->condition('ma.field_motivation_analysis_value', '%Analysis is Pending%', 'LIKE');
  $pending_nids = $pending_query->execute()->fetchCol();
  
  $logger->info('Found @count published articles with "Analysis is Pending" content', ['@count' => count($pending_nids)]);
  
  // Also get general published articles (but limit these)
  $published_query = \Drupal::entityQuery('node')
    ->condition('type', 'article')
    ->condition('status', 1) // Only published articles
    ->accessCheck(FALSE);
  
  $all_published_nids = $published_query->execute();
  
  // Combine and deduplicate: prioritize pending articles, then add others up to limit
  $combined_nids = array_unique(array_merge($pending_nids, array_slice($all_published_nids, 0, 50 - count($pending_nids))));
  $stats['published_checked'] = count($combined_nids);
  
  $logger->info('Checking @count total published articles (@pending with pending analysis + others)', [
    '@count' => count($combined_nids),
    '@pending' => count($pending_nids)
  ]);

  // Check published articles for unpublishing conditions
  $published_nodes = \Drupal::entityTypeManager()->getStorage('node')->loadMultiple($combined_nids);
  
  foreach ($published_nodes as $node) {
    try {
      // Get the data processing service to run post-processors
      $data_processing_service = \Drupal::service('news_extractor.data_processing');
      
      // Check if the article should be unpublished by running post-processors
      $original_status = $node->isPublished();
      
      // Run post-processors (this may unpublish the article)
      $reflection = new \ReflectionClass($data_processing_service);
      $method = $reflection->getMethod('postProcessPublishingStatus');
      $method->setAccessible(true);
      $method->invoke($data_processing_service, $node);
      
      // Save if status changed
      if ($original_status !== $node->isPublished()) {
        $node->save();
        $stats['articles_unpublished']++;
        $logger->info('Unpublished article @nid due to post-processor conditions: @title', [
          '@nid' => $node->id(),
          '@title' => $node->getTitle(),
        ]);
      }
      
    } catch (\Exception $e) {
      $logger->error('Error checking article @nid for post-processor conditions: @error', [
        '@nid' => $node->id(),
        '@error' => $e->getMessage(),
      ]);
    }
  }

  // STEP 2: Find unpublished articles that need reprocessing (only articles less than 3 days old)
  $logger->info('Step 2: Finding unpublished articles for reprocessing (less than 3 days old)');
  
  // Only reprocess articles created within the last 3 days to prevent infinite retrying
  $three_days_ago = \Drupal::time()->getRequestTime() - (3 * 24 * 60 * 60);
  
  $unpublished_query = \Drupal::entityQuery('node')
    ->condition('type', 'article')
    ->condition('status', 0) // Only unpublished articles
    ->condition('field_original_url.uri', '', '<>') // Must have URL for reprocessing
    ->condition('created', $three_days_ago, '>') // Only articles less than 3 days old
    ->accessCheck(FALSE);
  
  $unpublished_nids = $unpublished_query->execute();
  $stats['unpublished_found'] = count($unpublished_nids);
  
  $logger->info('Found @count unpublished articles (less than 3 days old) for reprocessing', ['@count' => $stats['unpublished_found']]);

  // Reprocess unpublished articles (limit to 20 per run to avoid timeouts)
  $reprocess_limit = min(20, count($unpublished_nids));
  $unpublished_nodes = \Drupal::entityTypeManager()->getStorage('node')->loadMultiple(array_slice($unpublished_nids, 0, $reprocess_limit));
  
  foreach ($unpublished_nodes as $node) {
    try {
      if (!$node->hasField('field_original_url') || $node->get('field_original_url')->isEmpty()) {
        $logger->warning('Node @nid has no URL for reprocessing', ['@nid' => $node->id()]);
        continue;
      }
      
      $url = $node->get('field_original_url')->uri;
      $logger->info('Reprocessing unpublished article @nid: @title', [
        '@nid' => $node->id(),
        '@title' => $node->getTitle(),
      ]);
      
      // Run through complete processing pipeline
      $success = $extraction_service->processArticle($node, $url);
      
      if ($success) {
        $stats['reprocessed_successfully']++;
        $logger->info('Successfully reprocessed article @nid', ['@nid' => $node->id()]);
      } else {
        $stats['reprocessing_failed']++;
        $logger->warning('Failed to reprocess article @nid', ['@nid' => $node->id()]);
      }
      
    } catch (\Exception $e) {
      $stats['reprocessing_failed']++;
      $logger->error('Error reprocessing article @nid: @error', [
        '@nid' => $node->id(),
        '@error' => $e->getMessage(),
      ]);
    }
  }

  // STEP 3: Delete old unpublished articles with persistent failures
  $logger->info('Step 3: Deleting old unpublished articles with persistent failures');
  
  // Find unpublished articles older than 24 hours
  $one_day_ago = \Drupal::time()->getRequestTime() - (24 * 60 * 60);
  
  $old_unpublished_query = \Drupal::entityQuery('node')
    ->condition('type', 'article')
    ->condition('status', 0) // Only unpublished articles
    ->condition('created', $one_day_ago, '<') // Older than 24 hours
    ->accessCheck(FALSE);
  
  $old_unpublished_nids = $old_unpublished_query->execute();
  
  if (!empty($old_unpublished_nids)) {
    // Limit deletions to prevent timeouts (max 50 per run)
    $delete_limit = min(50, count($old_unpublished_nids));
    $old_unpublished_nodes = \Drupal::entityTypeManager()->getStorage('node')->loadMultiple(array_slice($old_unpublished_nids, 0, $delete_limit));
    
    foreach ($old_unpublished_nodes as $node) {
      $title = $node->getTitle();
      $nid = $node->id();
      
      try {
        $node->delete();
        $stats['old_articles_deleted']++;
        
        $logger->info('Deleted old unpublished article @nid: @title', [
          '@nid' => $nid,
          '@title' => $title,
        ]);
      } catch (\Exception $e) {
        $logger->error('Error deleting old article @nid: @error', [
          '@nid' => $nid,
          '@error' => $e->getMessage(),
        ]);
      }
    }
  }

  // Log final statistics
  $logger->info('News extractor cron job completed. Statistics: @stats', [
    '@stats' => json_encode($stats),
  ]);

  // Also log human-readable summary
  $logger->info('Cron summary: Checked @checked published articles, unpublished @unpublished, found @found unpublished articles, reprocessed @success successfully, @failed failed, deleted @deleted old articles', [
    '@checked' => $stats['published_checked'],
    '@unpublished' => $stats['articles_unpublished'],
    '@found' => $stats['unpublished_found'],
    '@success' => $stats['reprocessed_successfully'],
    '@failed' => $stats['reprocessing_failed'],
    '@deleted' => $stats['old_articles_deleted'],
  ]);
}
